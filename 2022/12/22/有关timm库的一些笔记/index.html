<!DOCTYPE html>
<html lang="zh-CN">
  <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <link rel="preload" href="/css/first.css" as="style">
  

  <!-- 页面元数据 -->
  
  <title>有关timm库的笔记 - Leo Lee&#39;s blog</title>
  
    <meta name="keywords" content="机器学习,PyTorch">
  

  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  

  <!-- import link -->
  

  
    
<link rel="stylesheet" href="/css/first.css">

  

  
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  

  <script id="loadcss"></script>

  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a target="_blank" rel="noopener" href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support"><strong>了解详情 ></strong></a>'+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style>
    <div class="kill-noscript">
        <h1><b>抱歉，您的浏览器无法访问本站</b></h1>
        <h3>本页面需要浏览器支持（启用）JavaScript</h3><br/>
        <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=启用JavaScript"><strong>了解详情 ></strong></a>
    </div>
</noscript>

</head>

  <body>
    

<header id="l_header" class="l_header auto shadow blur show" style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a id="s-toc" class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
          
            Leo Lee's Blog
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/friends/
                  
                  
                  
                    id="friends"
                  >
                  <i class='fas fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
        <div id="full" class='cover-wrapper post search' style="display: none;">
          
            <div class='cover-bg lazyload placeholder' data-bg="https://z3.ax1x.com/2021/08/06/fn4CB8.png"></div>
          
          <div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">Leo Lee's Blog</p>
    
    
      <p class="subtitle">Welcome everyone</p>
    
  </div>
  <div class='bottom'>
    
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <input type="text" class="input u-search-input" placeholder="Search..." />
          <i class="icon fas fa-search fa-fw"></i>
        </form>
      </div>
    
    <div class='menu navigation'>
      <div class='list-h'>
        
          
            <a href="/"
              
              
              id="home">
              <p>博客</p>
            </a>
          
            <a href="/categories/"
              
              
              id="categories">
              <p>分类</p>
            </a>
          
            <a href="/tags/"
              
              
              id="tags">
              <p>标签</p>
            </a>
          
            <a href="/archives/"
              
              
              id="archives">
              <p>归档</p>
            </a>
          
            <a href="/friends/"
              
              
              id="friends">
              <p>友链</p>
            </a>
          
            <a href="/about/"
              
              
              id="about">
              <p>关于</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

          <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
        </div>
    
  
  </div>

      <div id="safearea">
        <div class="body-wrapper" id="pjax-container">
          

<div class='l_main'>
  <article class="article post white-box reveal md shadow article-type-post" id="post" itemscope itemprop="blogPost">
  


  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title">
        有关timm库的笔记
      </h1>
      <div class='new-meta-box'>
        
          
            
<div class='new-meta-item author'>
  <a class='author' href="/" rel="nofollow">
    <img no-lazy src="https://www.hualigs.cn/image/610d277ae201d.jpg">
    <p>李傲</p>
  </a>
</div>

          
        
          
            

          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2022年12月22日</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item browse leancloud">
    <a class='notlink'>
      
      <div id="lc-pv" data-title="有关timm库的笔记" data-path="/2022/12/22/%E6%9C%89%E5%85%B3timm%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/">
        <i class="fas fa-eye fa-fw" aria-hidden="true"></i>
        <span id='number'><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
        次浏览
      </div>
    </a>
  </div>


          
        
      </div>
    
  </div>


  
  
  <h3 id="什么是-timm-库">1 什么是 timm 库？</h3>
<p>PyTorchImageModels，简称 timm，是一个巨大的 PyTorch 代码集合，包括了一系列：</p>
<p>image models layers utilities optimizers schedulers data-loaders / augmentations training / validation scripts</p>
<p>旨在将各种 SOTA 模型整合在一起，并具有复现 ImageNet 训练结果的能力。</p>
<p>作者github链接：https://github.com/rwightman</p>
<p>timm库链接：https://github.com/rwightman/pytorch-image-models</p>
<p>所有的PyTorch模型及其对应arxiv链接如下：</p>
<p>Big Transfer ResNetV2 (BiT) - https://arxiv.org/abs/1912.11370 CspNet (Cross-Stage Partial Networks) - https://arxiv.org/abs/1911.11929 DeiT (Vision Transformer) - https://arxiv.org/abs/2012.12877 DenseNet - https://arxiv.org/abs/1608.06993 DLA - https://arxiv.org/abs/1707.06484 DPN (Dual-Path Network) - https://arxiv.org/abs/1707.01629 EfficientNet (MBConvNet Family) EfficientNet NoisyStudent (B0-B7, L2) - https://arxiv.org/abs/1911.04252 EfficientNet AdvProp (B0-B8) - https://arxiv.org/abs/1911.09665 EfficientNet (B0-B7) - https://arxiv.org/abs/1905.11946 EfficientNet-EdgeTPU (S, M, L) - https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html FBNet-C - https://arxiv.org/abs/1812.03443 MixNet - https://arxiv.org/abs/1907.09595 MNASNet B1, A1 (Squeeze-Excite), and Small - https://arxiv.org/abs/1807.11626 MobileNet-V2 - https://arxiv.org/abs/1801.04381 Single-Path NAS - https://arxiv.org/abs/1904.02877 GPU-Efficient Networks - https://arxiv.org/abs/2006.14090 HRNet - https://arxiv.org/abs/1908.07919 Inception-V3 - https://arxiv.org/abs/1512.00567 Inception-ResNet-V2 and Inception-V4 - https://arxiv.org/abs/1602.07261 MobileNet-V3 (MBConvNet w/ Efficient Head) - https://arxiv.org/abs/1905.02244 NASNet-A - https://arxiv.org/abs/1707.07012 NFNet-F - https://arxiv.org/abs/2102.06171 NF-RegNet / NF-ResNet - https://arxiv.org/abs/2101.08692 PNasNet - https://arxiv.org/abs/1712.00559 RegNet - https://arxiv.org/abs/2003.13678 RepVGG - https://arxiv.org/abs/2101.03697 ResNet/ResNeXt ResNet (v1b/v1.5) - https://arxiv.org/abs/1512.03385 ResNeXt - https://arxiv.org/abs/1611.05431 'Bag of Tricks' / Gluon C, D, E, S variations - https://arxiv.org/abs/1812.01187 Weakly-supervised (WSL) Instagram pretrained / ImageNet tuned ResNeXt101 - https://arxiv.org/abs/1805.00932 Semi-supervised (SSL) / Semi-weakly Supervised (SWSL) ResNet/ResNeXts - https://arxiv.org/abs/1905.00546 ECA-Net (ECAResNet) - https://arxiv.org/abs/1910.03151v4 Squeeze-and-Excitation Networks (SEResNet) - https://arxiv.org/abs/1709.01507 Res2Net - https://arxiv.org/abs/1904.01169 ResNeSt - https://arxiv.org/abs/2004.08955 ReXNet - https://arxiv.org/abs/2007.00992 SelecSLS - https://arxiv.org/abs/1907.00837 Selective Kernel Networks - https://arxiv.org/abs/1903.06586 TResNet - https://arxiv.org/abs/2003.13630 Vision Transformer - https://arxiv.org/abs/2010.11929 VovNet V2 and V1 - https://arxiv.org/abs/1911.06667 Xception - https://arxiv.org/abs/1610.02357 Xception (Modified Aligned, Gluon) - https://arxiv.org/abs/1802.02611 Xception (Modified Aligned, TF) - https://arxiv.org/abs/1802.02611</p>
<h3 id="timm库特点">2 timm库特点：</h3>
<p>所有的模型都有默认的API：</p>
<p>accessing/changing the classifier - get_classifier and reset_classifier 只对features做前向传播 - forward_features</p>
<p>所有模型都支持多尺度特征提取 (feature pyramids) (通过create_model函数)：</p>
<p>create_model(name, features_only=True, out_indices=..., output_stride=...)</p>
<p>out_indices 指定返回哪个feature maps to return, 从0开始，out_indices[i]对应着 C(i + 1) feature level。</p>
<p>output_stride 通过dilated convolutions控制网络的output stride。大多数网络默认 stride 32 。</p>
<p>所有的模型都有一致的pretrained weight loader，adapts last linear if necessary。</p>
<p>训练方式支持：</p>
<p>NVIDIA DDP w/ a single GPU per process, multiple processes with APEX present (AMP mixed-precision optional) PyTorch DistributedDataParallel w/ multi-gpu, single process (AMP disabled as it crashes when enabled) PyTorch w/ single GPU single process (AMP optional)</p>
<p>动态的全局池化方式可以选择：average pooling, max pooling, average + max, or concat([average, max])，默认是adaptive average。</p>
<p>Schedulers：</p>
<p>Schedulers 包括step,cosinew/ restarts,tanhw/ restarts,plateau 。</p>
<p>Optimizer：</p>
<p>rmsprop_tf adapted from PyTorch RMSProp by myself. Reproduces much improved Tensorflow RMSProp behaviour. radam by Liyuan Liu (https://arxiv.org/abs/1908.03265) novograd by Masashi Kimura (https://arxiv.org/abs/1905.11286) lookahead adapted from impl by Liam (https://arxiv.org/abs/1907.08610) fused<name> optimizers by name with NVIDIA Apex installed adamp and sgdp by Naver ClovAI (https://arxiv.org/abs/2006.08217) adafactor adapted from FAIRSeq impl (https://arxiv.org/abs/1804.04235) adahessian by David Samuel (https://arxiv.org/abs/2006.00719)</p>
<h3 id="timm库-vision_transformer.py代码解读">3 timm库 vision_transformer.py代码解读：</h3>
<p>代码来自：</p>
<p>https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py</p>
<p>对应的论文是ViT，是除了官方开源的代码之外的又一个优秀的PyTorch implement。</p>
<p>An Image Is Worth 16 x 16 Words: Transformers for Image Recognition at Scale https://arxiv.org/abs/2010.11929</p>
<p>另一篇工作DeiT也大量借鉴了timm库这份代码的实现：</p>
<p>Training data-efficient image transformers &amp; distillation through attention https://arxiv.org/abs/2012.12877</p>
<p>vision_transformer.py：</p>
<p>代码中定义的变量的含义如下：</p>
<p>img_size：tuple类型，里面是int类型，代表输入的图片大小，默认是224。 patch_size：tuple类型，里面是int类型，代表Patch的大小，默认是16。 in_chans：int类型，代表输入图片的channel数，默认是3。 num_classes：int类型classification head的分类数，比如CIFAR100就是100，默认是1000。 embed_dim：int类型Transformer的embedding dimension，默认是768。 depth：int类型，Transformer的Block的数量，默认是12。 num_heads：int类型，attention heads的数量，默认是12。 mlp_ratio：int类型，mlp hidden dim/embedding dim的值，默认是4。 qkv_bias：bool类型，attention模块计算qkv时需要bias吗，默认是True。 qk_scale：一般设置成None就行。 drop_rate：float类型，dropout rate，默认是0。 attn_drop_rate：float类型，attention模块的dropout rate，默认是0。 drop_path_rate：float类型，默认是0。 hybrid_backbone：nn.Module类型，在把图片转换成Patch之前，需要先通过一个Backbone吗？默认是None。 如果是None，就直接把图片转化成Patch。 如果不是None，就先通过这个Backbone，再转化成Patch。 norm_layer：nn.Module类型，归一化层类型，默认是None。</p>
<h4 id="导入必要的库和模型">1 导入必要的库和模型：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> timm.data <span class="keyword">import</span> IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD</span><br><span class="line"><span class="keyword">from</span> .helpers <span class="keyword">import</span> load_pretrained</span><br><span class="line"><span class="keyword">from</span> .layers <span class="keyword">import</span> StdConv2dSame, DropPath, to_2tuple, trunc_normal_</span><br><span class="line"><span class="keyword">from</span> .resnet <span class="keyword">import</span> resnet26d, resnet50d</span><br><span class="line"><span class="keyword">from</span> .resnetv2 <span class="keyword">import</span> ResNetV2</span><br><span class="line"><span class="keyword">from</span> .registry <span class="keyword">import</span> register_model</span><br></pre></td></tr></table></figure>
<h4 id="定义一个字典代表标准的模型如果需要更改模型超参数只需要改变_cfg的传入的参数即可">2 定义一个字典，代表标准的模型，如果需要更改模型超参数只需要改变_cfg的传入的参数即可。</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_cfg</span>(<span class="params">url=<span class="string">&#x27;&#x27;</span>, **kwargs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;url&#x27;</span>: url,</span><br><span class="line">        <span class="string">&#x27;num_classes&#x27;</span>: <span class="number">1000</span>, <span class="string">&#x27;input_size&#x27;</span>: (<span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>), <span class="string">&#x27;pool_size&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line">        <span class="string">&#x27;crop_pct&#x27;</span>: <span class="number">.9</span>, <span class="string">&#x27;interpolation&#x27;</span>: <span class="string">&#x27;bicubic&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;mean&#x27;</span>: IMAGENET_DEFAULT_MEAN, <span class="string">&#x27;std&#x27;</span>: IMAGENET_DEFAULT_STD,</span><br><span class="line">        <span class="string">&#x27;first_conv&#x27;</span>: <span class="string">&#x27;patch_embed.proj&#x27;</span>, <span class="string">&#x27;classifier&#x27;</span>: <span class="string">&#x27;head&#x27;</span>,</span><br><span class="line">        **kwargs</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="default_cfgs代表支持的所有模型也定义成字典的形式">3 default_cfgs代表支持的所有模型，也定义成字典的形式：</h4>
<p>vit_small_patch16_224里面的small代表小模型。 ViT的第一步要把图片分成一个个patch，然后把这些patch组合在一起作为对图像的序列化操作，比如一张224 × 224的图片分成大小为16 × 16的patch，那一共可以分成196个。所以这个图片就序列化成了(196, 256)的tensor。所以这里的： 16：就代表patch的大小。 224：就代表输入图片的大小。 按照这个命名方式，支持的模型有：vit_base_patch16_224，vit_base_patch16_384等等。</p>
<p>后面的vit_deit_base_patch16_224等等模型代表DeiT这篇论文的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">default_cfgs = &#123;</span><br><span class="line">    <span class="comment"># patch models (my experiments)</span></span><br><span class="line">    <span class="string">&#x27;vit_small_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth&#x27;</span>,</span><br><span class="line">    ),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># patch models (weights ported from official Google JAX impl)</span></span><br><span class="line">    <span class="string">&#x27;vit_base_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth&#x27;</span>,</span><br><span class="line">        mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>),</span><br><span class="line">    ),</span><br><span class="line">    <span class="string">&#x27;vit_base_patch32_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># no official model weights for this combo, only for in21k</span></span><br><span class="line">        mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_base_patch16_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_384-83fb41ba.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line">    <span class="string">&#x27;vit_base_patch32_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p32_384-830016f5.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_224-4ee7a4dc.pth&#x27;</span>,</span><br><span class="line">        mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch32_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># no official model weights for this combo, only for in21k</span></span><br><span class="line">        mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch16_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_384-b3be5167.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch32_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p32_384-9b920ba8.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># patch models, imagenet21k (weights ported from official Google JAX impl)</span></span><br><span class="line">    <span class="string">&#x27;vit_base_patch16_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_patch16_224_in21k-e5005f0a.pth&#x27;</span>,</span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_base_patch32_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_patch32_224_in21k-8db57226.pth&#x27;</span>,</span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch16_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch16_224_in21k-606da67d.pth&#x27;</span>,</span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_large_patch32_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_patch32_224_in21k-9046d2e7.pth&#x27;</span>,</span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">    <span class="string">&#x27;vit_huge_patch14_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># FIXME I have weights for this but &gt; 2GB limit for github release binaries</span></span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hybrid models (weights ported from official Google JAX impl)</span></span><br><span class="line">    <span class="string">&#x27;vit_base_resnet50_224_in21k&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_224_in21k-6f7c7740.pth&#x27;</span>,</span><br><span class="line">        num_classes=<span class="number">21843</span>, mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">0.9</span>, first_conv=<span class="string">&#x27;patch_embed.backbone.stem.conv&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;vit_base_resnet50_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_resnet50_384-9fd3c705.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), crop_pct=<span class="number">1.0</span>, first_conv=<span class="string">&#x27;patch_embed.backbone.stem.conv&#x27;</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hybrid models (my experiments)</span></span><br><span class="line">    <span class="string">&#x27;vit_small_resnet26d_224&#x27;</span>: _cfg(),</span><br><span class="line">    <span class="string">&#x27;vit_small_resnet50d_s3_224&#x27;</span>: _cfg(),</span><br><span class="line">    <span class="string">&#x27;vit_base_resnet26d_224&#x27;</span>: _cfg(),</span><br><span class="line">    <span class="string">&#x27;vit_base_resnet50d_224&#x27;</span>: _cfg(),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># deit models (FB weights)</span></span><br><span class="line">    <span class="string">&#x27;vit_deit_tiny_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;vit_deit_small_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;vit_deit_base_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth&#x27;</span>,),</span><br><span class="line">    <span class="string">&#x27;vit_deit_base_patch16_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line">    <span class="string">&#x27;vit_deit_tiny_distilled_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;vit_deit_small_distilled_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth&#x27;</span>),</span><br><span class="line">    <span class="string">&#x27;vit_deit_base_distilled_patch16_224&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth&#x27;</span>, ),</span><br><span class="line">    <span class="string">&#x27;vit_deit_base_distilled_patch16_384&#x27;</span>: _cfg(</span><br><span class="line">        url=<span class="string">&#x27;https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth&#x27;</span>,</span><br><span class="line">        input_size=(<span class="number">3</span>, <span class="number">384</span>, <span class="number">384</span>), crop_pct=<span class="number">1.0</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="ffn实现">4 FFN实现：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mlp</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="attention实现">5 Attention实现：</h4>
<p>在python 3.5以后，<span class="citation" data-cites="是一个操作符">@是一个操作符</span>，表示矩阵-向量乘法 A@x 就是矩阵-向量乘法A*x: np.dot(A, x)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Attention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, num_heads=<span class="number">8</span>, qkv_bias=<span class="literal">False</span>, qk_scale=<span class="literal">None</span>, attn_drop=<span class="number">0.</span>, proj_drop=<span class="number">0.</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads</span><br><span class="line">        <span class="comment"># NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights</span></span><br><span class="line">        self.scale = qk_scale <span class="keyword">or</span> head_dim ** -<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=qkv_bias)</span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        qkv = self.qkv(x).reshape(B, N, <span class="number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">        q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]   <span class="comment"># make torchscript happy (cannot use tensor as tuple)</span></span><br><span class="line"></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale</span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        attn = self.attn_drop(attn)</span><br><span class="line"></span><br><span class="line">        x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C)</span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.proj_drop(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># x: (B, N, C)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="包含attention和add-norm的block实现">6 包含Attention和Add &amp; Norm的Block实现：</h4>
<figure>
<img src="https://pic1.zhimg.com/80/v2-6bb2a6ebd653042308d731977de4de80_720w.webp" class="lazyload" data-srcset="https://pic1.zhimg.com/80/v2-6bb2a6ebd653042308d731977de4de80_720w.webp" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图1：Block类对应结构" /><figcaption aria-hidden="true">图1：Block类对应结构</figcaption>
</figure>
<p>不同之处是： 先进行Norm，再Attention；先进行Norm，再通过FFN (MLP)。</p>
<pre><code>class Block(nn.Module):

    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,
                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):
        super().__init__()
        self.norm1 = norm_layer(dim)
        self.attn = Attention(
            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)
        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here
        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()
        self.norm2 = norm_layer(dim)
        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)

    def forward(self, x):
        x = x + self.drop_path(self.attn(self.norm1(x)))
        x = x + self.drop_path(self.mlp(self.norm2(x)))
        return x</code></pre>
<h4 id="接下来要把图片转换成patch一种做法是直接把image转化成patch另一种做法是把backbone输出的特征转化成patch">7 接下来要把图片转换成Patch，一种做法是直接把Image转化成Patch，另一种做法是把Backbone输出的特征转化成Patch。</h4>
<h5 id="直接把image转化成patch">7.1直接把Image转化成Patch：</h5>
<p>输入的x的维度是：(B, C, H, W) 输出的PatchEmbedding的维度是：(B, 14$<em><span class="math inline">\(14, 768)，768表示embed_dim，14\)</span></em>$14表示一共有196个Patches。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PatchEmbed</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Image to Patch Embedding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        patch_size = to_2tuple(patch_size)</span><br><span class="line">        num_patches = (img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>]) * (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>])</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.num_patches = num_patches</span><br><span class="line"></span><br><span class="line">        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="comment"># FIXME look at relaxing size constraints</span></span><br><span class="line">        <span class="keyword">assert</span> H == self.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == self.img_size[<span class="number">1</span>], \</span><br><span class="line">            <span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line">        x = self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># x: (B, 14*14, 768)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h5 id="把backbone输出的特征转化成patch">7.2把Backbone输出的特征转化成Patch：</h5>
<p>输入的x的维度是：(B, C, H, W) 得到Backbone输出的维度是：(B, feature_size, feature_size, feature_dim) 输出的PatchEmbedding的维度是：(B, feature_size, feature_size, embed_dim)，一共有feature_size * feature_size个Patches。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HybridEmbed</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; CNN Feature Map Embedding</span></span><br><span class="line"><span class="string">    Extract feature map from CNN, flatten, project to embedding dim.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, backbone, img_size=<span class="number">224</span>, feature_size=<span class="literal">None</span>, in_chans=<span class="number">3</span>, embed_dim=<span class="number">768</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(backbone, nn.Module)</span><br><span class="line">        img_size = to_2tuple(img_size)</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.backbone = backbone</span><br><span class="line">        <span class="keyword">if</span> feature_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="comment"># FIXME this is hacky, but most reliable way of determining the exact dim of the output feature</span></span><br><span class="line">                <span class="comment"># map for all networks, the feature metadata has reliable channel and stride info, but using</span></span><br><span class="line">                <span class="comment"># stride to calc feature dim requires info about padding of each stage that isn&#x27;t captured.</span></span><br><span class="line">                training = backbone.training</span><br><span class="line">                <span class="keyword">if</span> training:</span><br><span class="line">                    backbone.<span class="built_in">eval</span>()</span><br><span class="line">                o = self.backbone(torch.zeros(<span class="number">1</span>, in_chans, img_size[<span class="number">0</span>], img_size[<span class="number">1</span>]))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(o, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">                    o = o[-<span class="number">1</span>]  <span class="comment"># last feature if backbone outputs list/tuple of features</span></span><br><span class="line">                feature_size = o.shape[-<span class="number">2</span>:]</span><br><span class="line">                feature_dim = o.shape[<span class="number">1</span>]</span><br><span class="line">                backbone.train(training)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            feature_size = to_2tuple(feature_size)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(self.backbone, <span class="string">&#x27;feature_info&#x27;</span>):</span><br><span class="line">                feature_dim = self.backbone.feature_info.channels()[-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                feature_dim = self.backbone.num_features</span><br><span class="line">        self.num_patches = feature_size[<span class="number">0</span>] * feature_size[<span class="number">1</span>]</span><br><span class="line">        self.proj = nn.Conv2d(feature_dim, embed_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.backbone(x)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">list</span>, <span class="built_in">tuple</span>)):</span><br><span class="line">            x = x[-<span class="number">1</span>]  <span class="comment"># last feature if backbone outputs list/tuple of features</span></span><br><span class="line">        x = self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="以上是vit所需的所有模块的定义下面是visiontransformer-这个类的实现">8 以上是ViT所需的所有模块的定义，下面是VisionTransformer 这个类的实现：</h4>
<h5 id="使用这个类时需要传入的变量其含义已经在本小节一开始介绍">8.1 使用这个类时需要传入的变量，其含义已经在本小节一开始介绍。</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VisionTransformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Vision Transformer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    A PyTorch impl of : `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale`  -</span></span><br><span class="line"><span class="string">        https://arxiv.org/abs/2010.11929</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>, num_classes=<span class="number">1000</span>, embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.</span>, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 drop_rate=<span class="number">0.</span>, attn_drop_rate=<span class="number">0.</span>, drop_path_rate=<span class="number">0.</span>, hybrid_backbone=<span class="literal">None</span>, norm_layer=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h5 id="得到分块后的patch的数量">8.2 得到分块后的Patch的数量：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__()</span><br><span class="line">self.num_classes = num_classes</span><br><span class="line">self.num_features = self.embed_dim = embed_dim  <span class="comment"># num_features for consistency with other models</span></span><br><span class="line">norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> hybrid_backbone <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    self.patch_embed = HybridEmbed(</span><br><span class="line">        hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    self.patch_embed = PatchEmbed(</span><br><span class="line">        img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)</span><br><span class="line">num_patches = self.patch_embed.num_patches</span><br></pre></td></tr></table></figure>
<h5 id="class-token">8.3 class token：</h5>
<p>一开始定义成(1, 1, 768)，之后再变成(B, 1, 768)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))</span><br></pre></td></tr></table></figure>
<h5 id="定义位置编码">8.4 定义位置编码：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, embed_dim))</span><br></pre></td></tr></table></figure>
<h5 id="把12个block连接起来">8.5 把12个Block连接起来：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">self.pos_drop = nn.Dropout(p=drop_rate)</span><br><span class="line"></span><br><span class="line">dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_rate, depth)]  <span class="comment"># stochastic depth decay rule</span></span><br><span class="line">self.blocks = nn.ModuleList([</span><br><span class="line">    Block(</span><br><span class="line">        dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,</span><br><span class="line">        drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line">self.norm = norm_layer(embed_dim)</span><br></pre></td></tr></table></figure>
<h5 id="表示层和分类头">8.6 表示层和分类头：</h5>
<p>表示层输出维度是representation_size，分类头输出维度是num_classes。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Representation layer</span></span><br><span class="line"><span class="keyword">if</span> representation_size:</span><br><span class="line">    self.num_features = representation_size</span><br><span class="line">    self.pre_logits = nn.Sequential(OrderedDict([</span><br><span class="line">        (<span class="string">&#x27;fc&#x27;</span>, nn.Linear(embed_dim, representation_size)),</span><br><span class="line">        (<span class="string">&#x27;act&#x27;</span>, nn.Tanh())</span><br><span class="line">    ]))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    self.pre_logits = nn.Identity()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Classifier head</span></span><br><span class="line">self.head = nn.Linear(self.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br></pre></td></tr></table></figure>
<h5 id="初始化各个模块">8.7 初始化各个模块：</h5>
<p>函数trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.)的目的是用截断的正态分布绘制的值填充输入张量，我们只需要输入均值mean，标准差std，下界a，上界b即可。</p>
<p>self.apply(self._init_weights)表示对各个模块的权重进行初始化。apply函数的代码是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> self.children():</span><br><span class="line">           module.apply(fn)</span><br><span class="line">       fn(self)</span><br><span class="line">       <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
<p>递归地将fn应用于每个子模块，相当于在递归调用fn，即_init_weights这个函数。 也就是把模型的所有子模块的nn.Linear和nn.LayerNorm层都初始化掉。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">trunc_normal_(self.pos_embed, std=<span class="number">.02</span>)</span><br><span class="line">trunc_normal_(self.cls_token, std=<span class="number">.02</span>)</span><br><span class="line">self.apply(self._init_weights)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_init_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">    trunc_normal_(m.weight, std=<span class="number">.02</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">and</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">    nn.init.constant_(m.weight, <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>
<h5 id="最后就是整个vit模型的forward实现">8.8 最后就是整个ViT模型的forward实现：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    B = x.shape[<span class="number">0</span>]</span><br><span class="line">    x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">    cls_tokens = self.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># stole cls_tokens impl from Phil Wang, thanks</span></span><br><span class="line">    x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">    x = x + self.pos_embed</span><br><span class="line">    x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line"></span><br><span class="line">    x = self.norm(x)[:, <span class="number">0</span>]</span><br><span class="line">    x = self.pre_logits(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    x = self.forward_features(x)</span><br><span class="line">    x = self.head(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="下面是training-data-efficient-image-transformers-distillation-through-attention这篇论文的deit这个类的实现">9 下面是Training data-efficient image transformers &amp; distillation through attention这篇论文的DeiT这个类的实现：</h4>
<p>整体结构与ViT相似，继承了上面的VisionTransformer类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DistilledVisionTransformer</span>(<span class="params">VisionTransformer</span>):</span></span><br></pre></td></tr></table></figure>
<p>再额外定义以下3个变量：</p>
<p>distillation token：dist_token 新的位置编码：pos_embed 蒸馏分类头：head_dist</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.embed_dim))</span><br><span class="line">num_patches = self.patch_embed.num_patches</span><br><span class="line">self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">2</span>, self.embed_dim))</span><br><span class="line">self.head_dist = nn.Linear(self.embed_dim, self.num_classes) <span class="keyword">if</span> self.num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br></pre></td></tr></table></figure>
<p>初始化新定义的变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trunc_normal_(self.dist_token, std=<span class="number">.02</span>)</span><br><span class="line">trunc_normal_(self.pos_embed, std=<span class="number">.02</span>)</span><br><span class="line">self.head_dist.apply(self._init_weights)</span><br></pre></td></tr></table></figure>
<p>前向函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    B = x.shape[<span class="number">0</span>]</span><br><span class="line">    x = self.patch_embed(x)</span><br><span class="line"></span><br><span class="line">    cls_tokens = self.cls_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># stole cls_tokens impl from Phil Wang, thanks</span></span><br><span class="line">    dist_token = self.dist_token.expand(B, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    x = torch.cat((cls_tokens, dist_token, x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = x + self.pos_embed</span><br><span class="line">    x = self.pos_drop(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> blk <span class="keyword">in</span> self.blocks:</span><br><span class="line">        x = blk(x)</span><br><span class="line"></span><br><span class="line">    x = self.norm(x)</span><br><span class="line">    <span class="keyword">return</span> x[:, <span class="number">0</span>], x[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    x, x_dist = self.forward_features(x)</span><br><span class="line">    x = self.head(x)</span><br><span class="line">    x_dist = self.head_dist(x_dist)</span><br><span class="line">    <span class="keyword">if</span> self.training:</span><br><span class="line">        <span class="keyword">return</span> x, x_dist</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># during inference, return the average of both classifier predictions</span></span><br><span class="line">        <span class="keyword">return</span> (x + x_dist) / <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="对位置编码进行插值">10 对位置编码进行插值：</h4>
<p>posemb代表未插值的位置编码权值，posemb_tok为位置编码的token部分，posemb_grid为位置编码的插值部分。 首先把要插值部分posemb_grid给reshape成(1, gs_old, gs_old, -1)的形式，再插值成(1, gs_new, gs_new, -1)的形式，最后与token部分在第1维度拼接在一起，得到插值后的位置编码posemb。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_pos_embed</span>(<span class="params">posemb, posemb_new</span>):</span></span><br><span class="line">    <span class="comment"># Rescale the grid of position embeddings when loading from state_dict. Adapted from</span></span><br><span class="line">    <span class="comment"># https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224</span></span><br><span class="line">    _logger.info(<span class="string">&#x27;Resized position embedding: %s to %s&#x27;</span>, posemb.shape, posemb_new.shape)</span><br><span class="line">    ntok_new = posemb_new.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">        posemb_tok, posemb_grid = posemb[:, :<span class="number">1</span>], posemb[<span class="number">0</span>, <span class="number">1</span>:]</span><br><span class="line">        ntok_new -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        posemb_tok, posemb_grid = posemb[:, :<span class="number">0</span>], posemb[<span class="number">0</span>]</span><br><span class="line">    gs_old = <span class="built_in">int</span>(math.sqrt(<span class="built_in">len</span>(posemb_grid)))</span><br><span class="line">    gs_new = <span class="built_in">int</span>(math.sqrt(ntok_new))</span><br><span class="line">    _logger.info(<span class="string">&#x27;Position embedding grid-size from %s to %s&#x27;</span>, gs_old, gs_new)</span><br><span class="line">    posemb_grid = posemb_grid.reshape(<span class="number">1</span>, gs_old, gs_old, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    posemb_grid = F.interpolate(posemb_grid, size=(gs_new, gs_new), mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">    posemb_grid = posemb_grid.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(<span class="number">1</span>, gs_new * gs_new, -<span class="number">1</span>)</span><br><span class="line">    posemb = torch.cat([posemb_tok, posemb_grid], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> posemb</span><br></pre></td></tr></table></figure>
<h4 id="create_vision_transformer函数用于创建vision-transformer">11 _create_vision_transformer函数用于创建vision transformer：</h4>
<p>checkpoint_filter_fn的作用是加载预训练权重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpoint_filter_fn</span>(<span class="params">state_dict, model</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; convert patch embedding weight from manual patchify + linear proj to conv&quot;&quot;&quot;</span></span><br><span class="line">    out_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;model&#x27;</span> <span class="keyword">in</span> state_dict:</span><br><span class="line">        <span class="comment"># For deit models</span></span><br><span class="line">        state_dict = state_dict[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;patch_embed.proj.weight&#x27;</span> <span class="keyword">in</span> k <span class="keyword">and</span> <span class="built_in">len</span>(v.shape) &lt; <span class="number">4</span>:</span><br><span class="line">            <span class="comment"># For old models that I trained prior to conv based patchification</span></span><br><span class="line">            O, I, H, W = model.patch_embed.proj.weight.shape</span><br><span class="line">            v = v.reshape(O, -<span class="number">1</span>, H, W)</span><br><span class="line">        <span class="keyword">elif</span> k == <span class="string">&#x27;pos_embed&#x27;</span> <span class="keyword">and</span> v.shape != model.pos_embed.shape:</span><br><span class="line">            <span class="comment"># To resize pos embedding when using model at different size from pretrained weights</span></span><br><span class="line">            v = resize_pos_embed(v, model.pos_embed)</span><br><span class="line">        out_dict[k] = v</span><br><span class="line">    <span class="keyword">return</span> out_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_create_vision_transformer</span>(<span class="params">variant, pretrained=<span class="literal">False</span>, distilled=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">    default_cfg = default_cfgs[variant]</span><br><span class="line">    default_num_classes = default_cfg[<span class="string">&#x27;num_classes&#x27;</span>]</span><br><span class="line">    default_img_size = default_cfg[<span class="string">&#x27;input_size&#x27;</span>][-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    num_classes = kwargs.pop(<span class="string">&#x27;num_classes&#x27;</span>, default_num_classes)</span><br><span class="line">    img_size = kwargs.pop(<span class="string">&#x27;img_size&#x27;</span>, default_img_size)</span><br><span class="line">    repr_size = kwargs.pop(<span class="string">&#x27;representation_size&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> repr_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> num_classes != default_num_classes:</span><br><span class="line">        <span class="comment"># Remove representation layer if fine-tuning. This may not always be the desired action,</span></span><br><span class="line">        <span class="comment"># but I feel better than doing nothing by default for fine-tuning. Perhaps a better interface?</span></span><br><span class="line">        _logger.warning(<span class="string">&quot;Removing representation layer for fine-tuning.&quot;</span>)</span><br><span class="line">        repr_size = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    model_cls = DistilledVisionTransformer <span class="keyword">if</span> distilled <span class="keyword">else</span> VisionTransformer</span><br><span class="line">    model = model_cls(img_size=img_size, num_classes=num_classes, representation_size=repr_size, **kwargs)</span><br><span class="line">    model.default_cfg = default_cfg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        load_pretrained(</span><br><span class="line">            model, num_classes=num_classes, in_chans=kwargs.get(<span class="string">&#x27;in_chans&#x27;</span>, <span class="number">3</span>),</span><br><span class="line">            filter_fn=partial(checkpoint_filter_fn, model=model))</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h4 id="定义和注册vision-transformer模型">12 定义和注册vision transformer模型：</h4>
<p>@ register_model这个函数来自timm库model文件夹下的registry.py文件，它的作用是： @ 指装饰器 <span class="citation" data-cites="register_model代表注册器">@register_model代表注册器</span>，注册这个新定义的模型。 存储到_model_entrypoints这个字典中，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_model_entrypoints[vit_base_patch16_224] = _create_vision_transformer(<span class="string">&#x27;vit_base_patch16_224&#x27;</span>, pretrained=pretrained, **model_kwargs)</span><br></pre></td></tr></table></figure>
<p>然后在factory.py的create_model函数中的下面这几行真正创建模型，你以后想创建的任何模型都会使用create_model这个函数，这里说清楚了为什么要用它：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> is_model(model_name):</span><br><span class="line">       create_fn = model_entrypoint(model_name)</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">       <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Unknown model (%s)&#x27;</span> % model_name)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">with</span> set_layer_config(scriptable=scriptable, exportable=exportable, no_jit=no_jit):</span><br><span class="line">       model = create_fn(pretrained=pretrained, **kwargs)</span><br></pre></td></tr></table></figure>
<p>比如刚才在main.py里面用了create_model创建模型，如下面代码所示。而create_model就来自factory.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = create_model(</span><br><span class="line">       args.model,</span><br><span class="line">       pretrained=<span class="literal">False</span>,</span><br><span class="line">       num_classes=args.nb_classes,</span><br><span class="line">       drop_rate=args.drop,</span><br><span class="line">       drop_path_rate=args.drop_path,</span><br><span class="line">       drop_block_rate=<span class="literal">None</span>,</span><br><span class="line">   )</span><br></pre></td></tr></table></figure>
<p>一共可以选择的模型包括：</p>
<p>ViT系列： vit_small_patch16_224 vit_base_patch16_224 vit_base_patch32_224 vit_base_patch16_384 vit_base_patch32_384 vit_large_patch16_224 vit_large_patch32_224 vit_large_patch16_384 vit_large_patch32_384 vit_base_patch16_224_in21k vit_base_patch32_224_in21k vit_large_patch16_224_in21k vit_large_patch32_224_in21k vit_huge_patch14_224_in21k vit_base_resnet50_224_in21k vit_base_resnet50_384 vit_small_resnet26d_224 vit_small_resnet50d_s3_224 vit_base_resnet26d_224 vit_base_resnet50d_224</p>
<p>DeiT系列： vit_deit_tiny_patch16_224 vit_deit_small_patch16_224 vit_deit_base_patch16_224 vit_deit_base_patch16_384 vit_deit_tiny_distilled_patch16_224 vit_deit_small_distilled_patch16_224 vit_deit_base_distilled_patch16_224 vit_deit_base_distilled_patch16_384</p>
<p>以上就是对timm库 vision_transformer.py代码的分析。</p>
<h3 id="如何使用timm库以及-vision_transformer.py代码搭建自己的模型">4 如何使用timm库以及 vision_transformer.py代码搭建自己的模型？</h3>
<p>在搭建我们自己的视觉Transformer模型时，我们可以按照下面的步骤操作：首先</p>
<p>继承timm库的VisionTransformer这个类。 添加上自己模型独有的一些变量。 重写forward函数。 通过timm库的注册器注册新模型。</p>
<p>我们以ViT模型的改进版DeiT为例：</p>
<p>首先，DeiT的所有模型列表如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__all__ = [</span><br><span class="line">    <span class="string">&#x27;deit_tiny_patch16_224&#x27;</span>, <span class="string">&#x27;deit_small_patch16_224&#x27;</span>, <span class="string">&#x27;deit_base_patch16_224&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;deit_tiny_distilled_patch16_224&#x27;</span>, <span class="string">&#x27;deit_small_distilled_patch16_224&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;deit_base_distilled_patch16_224&#x27;</span>, <span class="string">&#x27;deit_base_patch16_384&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;deit_base_distilled_patch16_384&#x27;</span>,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>导入VisionTransformer这个类，注册器register_model，以及初始化函数trunc_normal_：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> timm.models.vision_transformer <span class="keyword">import</span> VisionTransformer, _cfg</span><br><span class="line"><span class="keyword">from</span> timm.models.registry <span class="keyword">import</span> register_model</span><br><span class="line"><span class="keyword">from</span> timm.models.layers <span class="keyword">import</span> trunc_normal_</span><br></pre></td></tr></table></figure>
<p>DeiT的class名称是DistilledVisionTransformer，它直接继承了VisionTransformer这个类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DistilledVisionTransformer</span>(<span class="params">VisionTransformer</span>):</span></span><br></pre></td></tr></table></figure>
<p>添加上自己模型独有的一些变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line">    self.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.embed_dim))</span><br><span class="line">    num_patches = self.patch_embed.num_patches</span><br><span class="line">    <span class="comment"># 位置编码不是ViT中的(b, N, 256), 而变成了(b, N+2, 256), 原因是还有class token和distillation token.</span></span><br><span class="line">    self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">2</span>, self.embed_dim))</span><br><span class="line">    self.head_dist = nn.Linear(self.embed_dim, self.num_classes) <span class="keyword">if</span> self.num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    trunc_normal_(self.dist_token, std=<span class="number">.02</span>)</span><br><span class="line">    trunc_normal_(self.pos_embed, std=<span class="number">.02</span>)</span><br><span class="line">    self.head_dist.apply(self._init_weights)</span><br></pre></td></tr></table></figure>
<p>重写forward函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@register_model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deit_base_patch16_224</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">    model = VisionTransformer(</span><br><span class="line">        patch_size=<span class="number">16</span>, embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>, num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4</span>, qkv_bias=<span class="literal">True</span>,</span><br><span class="line">        norm_layer=partial(nn.LayerNorm, eps=<span class="number">1e-6</span>), **kwargs)</span><br><span class="line">    model.default_cfg = _cfg()</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        checkpoint = torch.hub.load_state_dict_from_url(</span><br><span class="line">            url=<span class="string">&quot;https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth&quot;</span>,</span><br><span class="line">            map_location=<span class="string">&quot;cpu&quot;</span>, check_hash=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        model.load_state_dict(checkpoint[<span class="string">&quot;model&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h3 id="timm库-train.py代码解读">5 timm库 train.py代码解读：</h3>
<p>timm库的训练使用结合apex支持的分布式训练，同步bn，以及混合精度的训练方式，其train.py的写法很具有代表性，值得拿出来讨论。因此这篇文章再多加一段，来专门讨论这个train.py。</p>
<p>结合apex支持的分布式训练，同步bn，以及混合精度的训练方式的详细讲解可以参考下面这篇文章：</p>
<p>https://zhuanlan.zhihu.com/p/353587472</p>
<p>在这篇文章中我们使用8步法结合apex支持的分布式训练，同步bn，以及混合精度：</p>
<h4 id="先罗列自己网络的参数">5.1先罗列自己网络的参数：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>():</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args</span><br></pre></td></tr></table></figure>
<p>local_rank指定了输出设备，默认为GPU可用列表中的第一个GPU。这里这个是必须加的。原因后面讲</p>
<h4 id="在主函数中开头写">5.2在主函数中开头写：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">	args = parse()</span><br><span class="line">	torch.cuda.set_device(args.local_rank)  <span class="comment"># 必须写！，还必须在下一句的前面，</span></span><br><span class="line">	<span class="comment">#torch.utils.launch也需要set_device， 所以必须写</span></span><br><span class="line">	torch.distributed.init_process_group(</span><br><span class="line">        <span class="string">&#x27;nccl&#x27;</span>,</span><br><span class="line">        init_method=<span class="string">&#x27;env://&#x27;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h4 id="导入数据接口这里有一点不一样需要用一个distributedsampler">5.3导入数据接口，这里有一点不一样。需要用一个DistributedSampler：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataset = DAVIS2017(root, <span class="string">&#x27;training&#x27;</span>)</span><br><span class="line">num_workers = <span class="number">4</span> <span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 多了一个DistributedSampler，作为dataloader的sampler</span></span><br><span class="line">train_sampler  = torch.utils.data.distributed.DistributedSampler(dataset)</span><br><span class="line">loader = DataLoader(dataset,batch_size=batchsize,shuffle=<span class="literal">False</span>, num_workers=num_workers,pin_memory=cuda,</span><br><span class="line">                                     drop_last=<span class="literal">True</span>, sampler=train_sampler)</span><br></pre></td></tr></table></figure>
<h4 id="之后定义模型">5.4之后定义模型：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net = XXXNet(using_amp=<span class="literal">True</span>)</span><br><span class="line">net.train()</span><br><span class="line">net = convert_syncbn_model(net)  <span class="comment"># 用apex支持的方法，使得普通bn成为同步bn。</span></span><br><span class="line"><span class="comment"># 切记在网络实现中，不要使用torch自带的SyncBatchnorm。</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.local_rank))</span><br><span class="line">net = net.to(device)  <span class="comment"># 把模型搬运到第一块GPU上</span></span><br></pre></td></tr></table></figure>
<h4 id="定义优化器损失函数定义优化器一定要在把模型搬运到gpu之后">5.5定义优化器，损失函数，定义优化器一定要在把模型搬运到GPU之后：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opt = Adam([&#123;<span class="string">&#x27;params&#x27;</span>: params_low_lr, <span class="string">&#x27;lr&#x27;</span>: <span class="number">4e-5</span>&#125;,</span><br><span class="line">         &#123;<span class="string">&#x27;params&#x27;</span>: params_high_lr, <span class="string">&#x27;lr&#x27;</span>: <span class="number">1e-4</span>&#125;], weight_decay=settings.WEIGHT_DECAY)</span><br><span class="line">crit = nn.BCELoss().to(device)</span><br></pre></td></tr></table></figure>
<h4 id="多gpu设置">5.6多GPU设置：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net, opt = amp.initialize(net, opt, opt_level=<span class="string">&quot;O1&quot;</span>)  <span class="comment"># 字母小写o,不是零。</span></span><br><span class="line"><span class="comment"># 关于initialize用法，见上一篇博客。</span></span><br><span class="line">net = DDP(net, delay_allreduce=<span class="literal">True</span>)  <span class="comment"># 必须在initialze之后</span></span><br></pre></td></tr></table></figure>
<h4 id="记得loss要这么用">5.7记得loss要这么用：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">opt.zero_grad()</span><br><span class="line"><span class="comment"># loss.backward()</span></span><br><span class="line"><span class="keyword">with</span> amp.scale_loss(loss, opt) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">     scaled_loss.backward()</span><br><span class="line">opt.step()</span><br></pre></td></tr></table></figure>
<h4 id="然后在代码底部加入">5.8然后在代码底部加入：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>那么这个train.py大体上依然遵循这8步：</p>
<p>https://github.com/rwightman/pytorch-image-models/blob/master/train.py</p>
<p>总结</p>
<p>本文简要介绍了优秀的PyTorch Image Model 库：timm库以及其中的 vision transformer 代码和训练代码。 Transformer 架构早已在自然语言处理任务中得到广泛应用，但在计算机视觉领域中仍然受到限制。在计算机视觉领域，目前已有大量工作表明模型对 CNN 的依赖不是必需的，当直接应用于图像块序列时，transformer 也能很好地执行图像分类任务。本文的目的是为学者介绍一个优秀的 vision transformer 的PyTorch实现，以便更快地开展相关实验。</p>

  
  
    
    <div class='footer'>
      
      
      
        <div class='copyright'>
          <blockquote>
            
              
                <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

              
            
          </blockquote>
        </div>
      
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2023-01-05T00:23:32+08:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2023年1月5日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>机器学习</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/PyTorch/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>PyTorch</p></a></div>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://example.com/2022/12/22/%E6%9C%89%E5%85%B3timm%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/&title=有关timm库的笔记 - Leo Lee's blog&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://example.com/2022/12/22/%E6%9C%89%E5%85%B3timm%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/&title=有关timm库的笔记 - Leo Lee's blog&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://service.weibo.com/share/share.php?url=http://example.com/2022/12/22/%E6%9C%89%E5%85%B3timm%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/&title=有关timm库的笔记 - Leo Lee's blog&summary="
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=">
          
        </a>
      
    
      
    
      
    
  </div>
</div>



        
      
    </div>
  </div>


  
  

  
    <div class="prev-next">
      
      
        <a class='next' href='/2022/10/27/%E6%9C%89%E5%85%B3GaitSet%E7%9A%84%E7%AC%94%E8%AE%B0/'>
          <p class='title'>有关GaitSet的笔记<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>
</p>
        </a>
      
    </div>
  
</article>


  

  <article class="post white-box reveal shadow" id="comments">
    <p ct><i class='fas fa-comments'></i> 评论</p>
    
    <div id="valine_container" class="valine_thread">
  <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
</div>

  </article>






</div>
<aside class='l_side'>
  
  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-timm-%E5%BA%93"><span class="toc-text">1 什么是 timm 库？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#timm%E5%BA%93%E7%89%B9%E7%82%B9"><span class="toc-text">2 timm库特点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#timm%E5%BA%93-vision_transformer.py%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB"><span class="toc-text">3 timm库 vision_transformer.py代码解读：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93%E5%92%8C%E6%A8%A1%E5%9E%8B"><span class="toc-text">1 导入必要的库和模型：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%AD%97%E5%85%B8%E4%BB%A3%E8%A1%A8%E6%A0%87%E5%87%86%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%A6%82%E6%9E%9C%E9%9C%80%E8%A6%81%E6%9B%B4%E6%94%B9%E6%A8%A1%E5%9E%8B%E8%B6%85%E5%8F%82%E6%95%B0%E5%8F%AA%E9%9C%80%E8%A6%81%E6%94%B9%E5%8F%98_cfg%E7%9A%84%E4%BC%A0%E5%85%A5%E7%9A%84%E5%8F%82%E6%95%B0%E5%8D%B3%E5%8F%AF"><span class="toc-text">2 定义一个字典，代表标准的模型，如果需要更改模型超参数只需要改变_cfg的传入的参数即可。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#default_cfgs%E4%BB%A3%E8%A1%A8%E6%94%AF%E6%8C%81%E7%9A%84%E6%89%80%E6%9C%89%E6%A8%A1%E5%9E%8B%E4%B9%9F%E5%AE%9A%E4%B9%89%E6%88%90%E5%AD%97%E5%85%B8%E7%9A%84%E5%BD%A2%E5%BC%8F"><span class="toc-text">3 default_cfgs代表支持的所有模型，也定义成字典的形式：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ffn%E5%AE%9E%E7%8E%B0"><span class="toc-text">4 FFN实现：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#attention%E5%AE%9E%E7%8E%B0"><span class="toc-text">5 Attention实现：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8C%85%E5%90%ABattention%E5%92%8Cadd-norm%E7%9A%84block%E5%AE%9E%E7%8E%B0"><span class="toc-text">6 包含Attention和Add &amp; Norm的Block实现：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A5%E4%B8%8B%E6%9D%A5%E8%A6%81%E6%8A%8A%E5%9B%BE%E7%89%87%E8%BD%AC%E6%8D%A2%E6%88%90patch%E4%B8%80%E7%A7%8D%E5%81%9A%E6%B3%95%E6%98%AF%E7%9B%B4%E6%8E%A5%E6%8A%8Aimage%E8%BD%AC%E5%8C%96%E6%88%90patch%E5%8F%A6%E4%B8%80%E7%A7%8D%E5%81%9A%E6%B3%95%E6%98%AF%E6%8A%8Abackbone%E8%BE%93%E5%87%BA%E7%9A%84%E7%89%B9%E5%BE%81%E8%BD%AC%E5%8C%96%E6%88%90patch"><span class="toc-text">7 接下来要把图片转换成Patch，一种做法是直接把Image转化成Patch，另一种做法是把Backbone输出的特征转化成Patch。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E6%8A%8Aimage%E8%BD%AC%E5%8C%96%E6%88%90patch"><span class="toc-text">7.1直接把Image转化成Patch：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%8Abackbone%E8%BE%93%E5%87%BA%E7%9A%84%E7%89%B9%E5%BE%81%E8%BD%AC%E5%8C%96%E6%88%90patch"><span class="toc-text">7.2把Backbone输出的特征转化成Patch：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A5%E4%B8%8A%E6%98%AFvit%E6%89%80%E9%9C%80%E7%9A%84%E6%89%80%E6%9C%89%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8B%E9%9D%A2%E6%98%AFvisiontransformer-%E8%BF%99%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">8 以上是ViT所需的所有模块的定义，下面是VisionTransformer 这个类的实现：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%BF%99%E4%B8%AA%E7%B1%BB%E6%97%B6%E9%9C%80%E8%A6%81%E4%BC%A0%E5%85%A5%E7%9A%84%E5%8F%98%E9%87%8F%E5%85%B6%E5%90%AB%E4%B9%89%E5%B7%B2%E7%BB%8F%E5%9C%A8%E6%9C%AC%E5%B0%8F%E8%8A%82%E4%B8%80%E5%BC%80%E5%A7%8B%E4%BB%8B%E7%BB%8D"><span class="toc-text">8.1 使用这个类时需要传入的变量，其含义已经在本小节一开始介绍。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BE%97%E5%88%B0%E5%88%86%E5%9D%97%E5%90%8E%E7%9A%84patch%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-text">8.2 得到分块后的Patch的数量：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#class-token"><span class="toc-text">8.3 class token：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-text">8.4 定义位置编码：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%8A12%E4%B8%AAblock%E8%BF%9E%E6%8E%A5%E8%B5%B7%E6%9D%A5"><span class="toc-text">8.5 把12个Block连接起来：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8%E7%A4%BA%E5%B1%82%E5%92%8C%E5%88%86%E7%B1%BB%E5%A4%B4"><span class="toc-text">8.6 表示层和分类头：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%84%E4%B8%AA%E6%A8%A1%E5%9D%97"><span class="toc-text">8.7 初始化各个模块：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E5%90%8E%E5%B0%B1%E6%98%AF%E6%95%B4%E4%B8%AAvit%E6%A8%A1%E5%9E%8B%E7%9A%84forward%E5%AE%9E%E7%8E%B0"><span class="toc-text">8.8 最后就是整个ViT模型的forward实现：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E9%9D%A2%E6%98%AFtraining-data-efficient-image-transformers-distillation-through-attention%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E7%9A%84deit%E8%BF%99%E4%B8%AA%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">9 下面是Training data-efficient image transformers &amp; distillation through attention这篇论文的DeiT这个类的实现：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E8%BF%9B%E8%A1%8C%E6%8F%92%E5%80%BC"><span class="toc-text">10 对位置编码进行插值：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#create_vision_transformer%E5%87%BD%E6%95%B0%E7%94%A8%E4%BA%8E%E5%88%9B%E5%BB%BAvision-transformer"><span class="toc-text">11 _create_vision_transformer函数用于创建vision transformer：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%92%8C%E6%B3%A8%E5%86%8Cvision-transformer%E6%A8%A1%E5%9E%8B"><span class="toc-text">12 定义和注册vision transformer模型：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8timm%E5%BA%93%E4%BB%A5%E5%8F%8A-vision_transformer.py%E4%BB%A3%E7%A0%81%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-text">4 如何使用timm库以及 vision_transformer.py代码搭建自己的模型？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#timm%E5%BA%93-train.py%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB"><span class="toc-text">5 timm库 train.py代码解读：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%88%E7%BD%97%E5%88%97%E8%87%AA%E5%B7%B1%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-text">5.1先罗列自己网络的参数：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E4%B8%BB%E5%87%BD%E6%95%B0%E4%B8%AD%E5%BC%80%E5%A4%B4%E5%86%99"><span class="toc-text">5.2在主函数中开头写：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3%E8%BF%99%E9%87%8C%E6%9C%89%E4%B8%80%E7%82%B9%E4%B8%8D%E4%B8%80%E6%A0%B7%E9%9C%80%E8%A6%81%E7%94%A8%E4%B8%80%E4%B8%AAdistributedsampler"><span class="toc-text">5.3导入数据接口，这里有一点不一样。需要用一个DistributedSampler：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%8B%E5%90%8E%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="toc-text">5.4之后定义模型：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E5%99%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%80%E5%AE%9A%E8%A6%81%E5%9C%A8%E6%8A%8A%E6%A8%A1%E5%9E%8B%E6%90%AC%E8%BF%90%E5%88%B0gpu%E4%B9%8B%E5%90%8E"><span class="toc-text">5.5定义优化器，损失函数，定义优化器一定要在把模型搬运到GPU之后：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9Agpu%E8%AE%BE%E7%BD%AE"><span class="toc-text">5.6多GPU设置：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%B0%E5%BE%97loss%E8%A6%81%E8%BF%99%E4%B9%88%E7%94%A8"><span class="toc-text">5.7记得loss要这么用：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%84%B6%E5%90%8E%E5%9C%A8%E4%BB%A3%E7%A0%81%E5%BA%95%E9%83%A8%E5%8A%A0%E5%85%A5"><span class="toc-text">5.8然后在代码底部加入：</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>



		  
		  <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="有关timm库的笔记";
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  // header 这里无论是否开启pjax都需要
  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
  
    // cover
    var cover_wrapper=document.querySelector('.cover-wrapper');
    
    cover_wrapper.id="none";
    cover_wrapper.style.display="none";
    
  
</script>

        </div>
        
  
  <footer class="footer clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
          
            
          
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        
          <div><p><span id="lc-sv">本站总访问量为 <span id="number"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 次</span> <span id="lc-uv">访客数为 <span id="number"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span> 人</span></p>
</div>
        
      
    
      
        本站使用
        <a href="https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1" target="_blank" class="codename">Volantis</a>
        作为主题
      
    
      
        <div class='copyright'>
        <p><a href="/">Copyright © 2021 李傲</a></p>

        </div>
      
    
  </footer>


        <a id="s-top" class="fas fa-arrow-up fa-fw" href="javascript:void(0)"></a>
      </div>
    </div>
    <div>
      <script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script>
<script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script>
<!-- required -->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js"></script>

<script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script>


<!-- internal -->




<script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script>



  <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script>
<script defer src="https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script>











  
  
<script src="https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js"></script>


<script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"js":"https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js","path":null,"placeholder":"快来评论吧~","appId":"MWQrxu8b3KFPpdL0lcGw9wzA-gzGzoHsz","appKey":"sXrj3aemj3UxvOw5CmCyvxjv","meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script>






  
<script src="/js/app.js"></script>



<!-- optional -->

  <script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
		document.addEventListener("pjax:success", listenSearch);
	
}
</script>











  <script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'http://example.com' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'http://example.com' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'http://example.com' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script>




  <script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
var btn=$("#wrapper .toggle-mode-btn,#rightmenu-wrapper .toggle-mode-btn");
function bindToggleButton() {
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	btn.unbind('click');
},'toggle-mode-btn-unbind');
</script>








<script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script>

<!-- more -->

 
	   
	    


<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script>
 
	  
    </div>
  </body>
</html>
